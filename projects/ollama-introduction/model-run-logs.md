# Model Execution Logs

## llama3:8b
Command:
ollama run llama3:8b

Observation:
- Model loaded successfully
- Interactive prompt available
- Response latency acceptable for local execution

## mistral:7b
Command:
ollama run mistral:7b

Observation:
- Faster responses
- Lower memory usage
